{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Bad key \"text.kerning_factor\" on line 4 in\n",
      "/home/emfreese/anaconda3/envs/conda_env/lib/python3.7/site-packages/matplotlib/mpl-data/stylelib/_classic_test_patch.mplstyle.\n",
      "You probably need to get an updated matplotlibrc file from\n",
      "http://github.com/matplotlib/matplotlib/blob/master/matplotlibrc.template\n",
      "or from the matplotlib source distribution\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import xarray as xr\n",
    "\n",
    "import regionmask\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import cartopy.crs as ccrs\n",
    "from matplotlib import cm\n",
    "from matplotlib.colors import ListedColormap, LinearSegmentedColormap\n",
    "import cartopy.feature as cfeat\n",
    "from scipy.interpolate import RectBivariateSpline\n",
    "from datetime import datetime, timedelta\n",
    "import geopandas\n",
    "\n",
    "import calendar\n",
    "\n",
    "import glob\n",
    "\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "import utils\n",
    "\n",
    "np.seterr(invalid='ignore'); # disable a warning from matplotlib and cartopy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GEOS Chem Runs\n",
    "\n",
    "Using egrid, NEI, and our model emissions inventories for NO, NO2, SO2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ds_MODEL' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-d7ac898219bb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mds_egrid\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mds_NEI\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0mds_MODEL\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m ]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'ds_MODEL' is not defined"
     ]
    }
   ],
   "source": [
    "egrid_path = '../../GCrundirs/type_NA-out_conc-yr_2016-gridmod_final-validation-egrid/OutputDir/'\n",
    "NEI_path = '../../GCrundirs/type_NA-out_conc-yr_2016-gtropchem/merra2_05x0625_tropchem_na/OutputDir/'\n",
    "normal_model_path = '../../GCrundirs/type_NA-out_conc-yr_2016-gridmod_final-validation/OutputDir/'\n",
    "speciesconc_output = 'GEOSChem.SpeciesConc.2016*.nc4'\n",
    "aerosol_output = 'GEOSChem.AerosolMass.2016*.nc4'\n",
    "\n",
    "ds_egrid = utils.import_GC_runs_general(egrid_path, speciesconc_output, aerosol_output, 'egrid')\n",
    "ds_NEI = utils.import_GC_runs_general(NEI_path, speciesconc_output, aerosol_output, 'NEI')\n",
    "ds_normal_model = utils.import_GC_runs_general(normal_model_path, speciesconc_output, aerosol_output, 'normal_model')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "datasets = [\n",
    "    ds_egrid,\n",
    "    ds_NEI,\n",
    "    ds_normal_model\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "poll_ds = utils.combine_and_convert_ds(utils.gas_species_list, utils.aerosol_species_dict.keys(), datasets, ['egrid', 'NEI', 'normal_model'],['egrid','NEI'], \n",
    "                                       'normal_model', 'model_NEI_egrid')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<xarray.backends.zarr.ZarrStore at 0x7fd3369cd4c0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xr.Dataset.to_zarr(poll_ds, 'model_NEI_egrid_GC_ds.zarr') #save the dataset "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "poll_ds = xr.open_zarr('model_NEI_egrid_GC_ds.zarr/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EPA Observational data\n",
    "data is from https://aqs.epa.gov/aqsweb/airdata/download_files.html\n",
    "for the year 2016\n",
    "choosing O3, NO, SO2, PM25 (FEM/FRM)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPA_obs_df = utils.import_and_edit_EPAobs('../../GEOS_CHEM/obs_data/daily*.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IMPROVE Observational data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "mw_dict = {'ammNO3': 80.043,\n",
    "           'ammSO4': 132.14} #g/mol \n",
    "g_ug = 1e6\n",
    "\n",
    "for species in mw_dict.keys():\n",
    "    ammon_df[f'{species}f:Value'] *= mw_dict[species] * g_ug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "pm_df = utils.import_IMPROVE('../../GEOS_CHEM/obs_data/IMPROVE_2016_PM.txt', 'PM25', 'MF')\n",
    "s_df = utils.import_IMPROVE('../../GEOS_CHEM/obs_data/IMPROVE_2016_Sulfate.txt', 'SO4', 'SO4f')\n",
    "n_df = utils.import_IMPROVE('../../GEOS_CHEM/obs_data/IMPROVE_2016_Nitrate.txt', 'NIT', 'NO3f')\n",
    "oc_df = utils.import_IMPROVE('../../GEOS_CHEM/obs_data/IMPROVE_2016_ammonia.txt', 'NH4', 'NH4f')\n",
    "ammon_df = utils.import_IMPROVE('../../GEOS_CHEM/obs_data/IMPROVE_2016_OC.txt', 'OC_EC', 'ECf')\n",
    "\n",
    "IMPROVE_df = pd.concat([pm_df, s_df, n_df,oc_df, ammon_df], axis = 0) #concatenate all dataframes and reset the index\n",
    "IMPROVE_df['Date'] = pd.to_datetime(IMPROVE_df['Date']) #change to datetime\n",
    "IMPROVE_df = IMPROVE_df.loc[IMPROVE_df['Arithmetic Mean'] >= 0] #get rid of -999 readings where there is no data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lists/Dicts of Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define Lat and Lon of the nested grid US\n",
    "levels_dict = {'PM25':np.arange(0., 20., .5), 'SO2':np.arange(0., 5., .1), \n",
    "               'NO2':np.arange(0., 5., .1), 'NOx':np.arange(0., 5., .1), 'O3':np.arange(0., 70., 1.),\n",
    "               'dif':np.arange(-.3, .31, .01), 'regional_dif':np.arange(-1.5, 1.51, .01)}\n",
    "\n",
    "\n",
    "#model_names = []\n",
    "#for d in datasets:    \n",
    "    #model_names.append(d.attrs['name'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stats on Observations vs. Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interpolate data to get GC run data at observational points"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### EPA Interpolation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### For egrid, NEI, normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### interpolate data for EPA\n",
    "interp_EPA_df = pd.DataFrame(columns=['Arithmetic Mean', 'Longitude', 'Latitude','model','species','date'])\n",
    "\n",
    "for model in model_names:\n",
    "    for species in list(utils.species_dict.keys()):\n",
    "        for month in pd.DatetimeIndex(EPA_obs_df.loc[EPA_obs_df.date.dt.month.isin(utils.month_string)]['date'].values).month.unique().values:\n",
    "\n",
    "            #data selected for date\n",
    "            data = poll_ds.sel(model_name = model)[f'{species}'].groupby('time.month').mean().sel(month = month)\n",
    "            \n",
    "            #new lat and lon in radians\n",
    "            lats_new = EPA_obs_df.loc[(EPA_obs_df['species'] == utils.species_dict[species])]['Latitude'].unique()\n",
    "            lons_new = EPA_obs_df.loc[(EPA_obs_df['species'] == utils.species_dict[species])]['Longitude'].unique()\n",
    "            \n",
    "            #interpolation function\n",
    "            #interp_spline= RectBivariateSpline(lats, lons, data)\n",
    "            #interp_data = interp_spline(lats_new,lons_new,grid = False)\n",
    "            interp_data = []\n",
    "            for idx in range(lats_new.size):\n",
    "                interp_data.append(data.sel(lat=lats_new[idx], lon=lons_new[idx], method='nearest').values.item())\n",
    "            \n",
    "            tmp_df = pd.DataFrame({'Arithmetic Mean':interp_data, 'Longitude':lons_new, 'Latitude':lats_new, 'model': model, 'species': utils.species_dict[species], 'date': month})\n",
    "            interp_EPA_df = interp_EPA_df.append(tmp_df, sort=False, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, len(interp_EPA_df)):\n",
    "    interp_EPA_df.loc[i,('date')] = datetime(2016,interp_EPA_df['date'][i],calendar.monthrange(2016,interp_EPA_df['date'][i])[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### For Nonuc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "poll_nonuc1 = xr.open_zarr('../ego_nonuclear_project/pm_nonuc_ds.zarr/')\n",
    "poll_nonuc2 = xr.open_zarr('../ego_nonuclear_project/nonuc_normal_GC/')\n",
    "poll_nonuc2 = poll_nonuc2.drop(labels = ['HNO3', 'NH3', 'SO4'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert to ug/m3 from mol/mol\n",
    "mw_species = {\n",
    "    'NH4': 18.,\n",
    "    'NIT': 62.,\n",
    "    'SO4': 96.,\n",
    "    'BCPI': 12.,\n",
    "    'OCPI': 12.,\n",
    "    'BCPO': 12.,\n",
    "    'OCPO': 12.,\n",
    "    'DST1': 29.,\n",
    "    'DST2': 29.,\n",
    "    'SALA': 31.4,\n",
    "}\n",
    "#list of pm species\n",
    "pm_species = list(mw_species.keys())\n",
    "\n",
    "poll_nonuc1 = utils.ppb_to_ug(poll_nonuc1, pm_species, mw_species)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "poll_nonuc = xr.merge([poll_nonuc1, poll_nonuc2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "### interpolate data for EPA\n",
    "interp_EPA_nonuc_df = pd.DataFrame(columns=['Arithmetic Mean', 'Longitude', 'Latitude','model','species','date'])\n",
    "\n",
    "for species in ['PM25', 'SO2', 'NO2', 'O3']:\n",
    "    for month in pd.DatetimeIndex(EPA_obs_df.loc[EPA_obs_df.date.dt.month.isin(utils.month_string)]['date'].values).month.unique().values:\n",
    "\n",
    "        #data selected for date\n",
    "        data = poll_nonuc.sel(model_name = 'nonuc')[f'{species}'].groupby('time.month').mean().sel(month = month)\n",
    "\n",
    "        #new lat and lon in radians\n",
    "        lats_new = EPA_obs_df.loc[(EPA_obs_df['species'] == utils.species_dict[species])]['Latitude'].unique()\n",
    "        lons_new = EPA_obs_df.loc[(EPA_obs_df['species'] == utils.species_dict[species])]['Longitude'].unique()\n",
    "\n",
    "        #interpolation function\n",
    "        interp_data = []\n",
    "        for idx in range(lats_new.size):\n",
    "            interp_data.append(data.sel(lat=lats_new[idx], lon=lons_new[idx], method='nearest').values.item())\n",
    "\n",
    "        tmp_df = pd.DataFrame({'Arithmetic Mean':interp_data, 'Longitude':lons_new, 'Latitude':lats_new, 'model': 'nonuc', 'species': species, 'date': month})\n",
    "        interp_EPA_nonuc_df = interp_EPA_nonuc_df.append(tmp_df, sort=False, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, len(interp_EPA_nonuc_df)):\n",
    "    interp_EPA_nonuc_df.loc[i,('date')] = datetime(2016,interp_EPA_nonuc_df['date'][i],calendar.monthrange(2016,interp_EPA_nonuc_df['date'][i])[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### IMPROVE Interpolation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### for EGRID, NEI, NORMAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import dataset with the SO4 and NIT contributions from the model\n",
    "poll_2_ds = xr.open_zarr('pm_ds.zarr')\n",
    "#convert to ug/m3 from mol/mol\n",
    "mw_species = {\n",
    "    'NH4': 18.,\n",
    "    'NIT': 62.,\n",
    "    'SO4': 96.,\n",
    "    'BCPI': 12.,\n",
    "    'OCPI': 12.,\n",
    "    'BCPO': 12.,\n",
    "    'OCPO': 12.,\n",
    "    'DST1': 29.,\n",
    "    'DST2': 29.,\n",
    "    'SALA': 31.4,\n",
    "}\n",
    "#list of pm species\n",
    "pm_species = list(mw_species.keys())\n",
    "\n",
    "poll_2_ds = utils.ppb_to_ug(poll_2_ds, pm_species, mw_species)\n",
    "    \n",
    "poll_ds = xr.merge([poll_ds, poll_2_ds])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "### interpolate data for EPA\n",
    "interp_IMPROVE_df = pd.DataFrame(columns=['Arithmetic Mean', 'Longitude', 'Latitude','model','species','date'])\n",
    "\n",
    "for model in model_names:\n",
    "    for species in ['PM25','NIT','SO4','NH3','NH4','HNO3']:\n",
    "        for month in pd.DatetimeIndex(IMPROVE_df.loc[IMPROVE_df.Date.dt.month.isin(utils.month_string)]['Date'].values).month.unique().values:\n",
    "\n",
    "            #data selected for date\n",
    "            data = poll_ds.sel(model_name = model)[f'{species}'].groupby('time.month').mean().sel(month = month)\n",
    "            \n",
    "            #new lat and lon in radians\n",
    "            lats_new = IMPROVE_df.loc[(IMPROVE_df['species'] == species)]['Latitude'].unique()\n",
    "            lons_new = IMPROVE_df.loc[(IMPROVE_df['species'] == species)]['Longitude'].unique()\n",
    "            if species == 'NH3':\n",
    "                lats_new = IMPROVE_df.loc[(IMPROVE_df['species'] == 'NH4')]['Latitude'].unique()\n",
    "                lons_new = IMPROVE_df.loc[(IMPROVE_df['species'] == 'NH4')]['Longitude'].unique()\n",
    "            if species == 'HNO3':\n",
    "                lats_new = IMPROVE_df.loc[(IMPROVE_df['species'] == 'NIT')]['Latitude'].unique()\n",
    "                lons_new = IMPROVE_df.loc[(IMPROVE_df['species'] == 'NIT')]['Longitude'].unique()\n",
    "            #interpolation function\n",
    "            interp_data = []\n",
    "            for idx in range(lats_new.size):\n",
    "                interp_data.append(data.sel(lat=lats_new[idx], lon=lons_new[idx], method='nearest').values.item())\n",
    "            \n",
    "            tmp_df = pd.DataFrame({'Arithmetic Mean':interp_data, 'Longitude':lons_new, 'Latitude':lats_new, 'model': model, 'species': species, 'date': month})\n",
    "            interp_IMPROVE_df = interp_IMPROVE_df.append(tmp_df, sort=False, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, len(interp_IMPROVE_df)):\n",
    "    interp_IMPROVE_df.loc[i,('date')] = datetime(2016,interp_IMPROVE_df['date'][i],calendar.monthrange(2016,interp_IMPROVE_df['date'][i])[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### For NONUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "poll_nonuc1 = xr.open_zarr('../ego_nonuclear_project/pm_nonuc_ds.zarr/')\n",
    "poll_nonuc2 = xr.open_zarr('../ego_nonuclear_project/nonuc_normal_GC/')\n",
    "poll_nonuc2 = poll_nonuc2.drop(labels = ['HNO3', 'NH3', 'SO4'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert to ug/m3 from mol/mol\n",
    "mw_species = {\n",
    "    'NH4': 18.,\n",
    "    'NIT': 62.,\n",
    "    'SO4': 96.,\n",
    "    'BCPI': 12.,\n",
    "    'OCPI': 12.,\n",
    "    'BCPO': 12.,\n",
    "    'OCPO': 12.,\n",
    "    'DST1': 29.,\n",
    "    'DST2': 29.,\n",
    "    'SALA': 31.4,\n",
    "}\n",
    "#list of pm species\n",
    "pm_species = list(mw_species.keys())\n",
    "\n",
    "poll_nonuc1 = utils.ppb_to_ug(poll_nonuc1, pm_species, mw_species)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "poll_nonuc = xr.merge([poll_nonuc1, poll_nonuc2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "### interpolate data for EPA\n",
    "interp_IMPROVE_nonuc_df = pd.DataFrame(columns=['Arithmetic Mean', 'Longitude', 'Latitude','model','species','date'])\n",
    "\n",
    "for species in ['PM25','NIT','SO4','NH3','NH4','HNO3']:\n",
    "    for month in pd.DatetimeIndex(IMPROVE_df.loc[IMPROVE_df.Date.dt.month.isin(utils.month_string)]['Date'].values).month.unique().values:\n",
    "\n",
    "        #data selected for date\n",
    "        data = poll_nonuc.sel(model_name = 'nonuc')[f'{species}'].groupby('time.month').mean().sel(month = month)\n",
    "\n",
    "        #new lat and lon in radians\n",
    "        lats_new = IMPROVE_df.loc[(IMPROVE_df['species'] == species)]['Latitude'].unique()\n",
    "        lons_new = IMPROVE_df.loc[(IMPROVE_df['species'] == species)]['Longitude'].unique()\n",
    "        if species == 'NH3':\n",
    "            lats_new = IMPROVE_df.loc[(IMPROVE_df['species'] == 'NH4')]['Latitude'].unique()\n",
    "            lons_new = IMPROVE_df.loc[(IMPROVE_df['species'] == 'NH4')]['Longitude'].unique()\n",
    "        if species == 'HNO3':\n",
    "            lats_new = IMPROVE_df.loc[(IMPROVE_df['species'] == 'NIT')]['Latitude'].unique()\n",
    "            lons_new = IMPROVE_df.loc[(IMPROVE_df['species'] == 'NIT')]['Longitude'].unique()\n",
    "        #interpolation function\n",
    "        interp_data = []\n",
    "        for idx in range(lats_new.size):\n",
    "            interp_data.append(data.sel(lat=lats_new[idx], lon=lons_new[idx], method='nearest').values.item())\n",
    "\n",
    "        tmp_df = pd.DataFrame({'Arithmetic Mean':interp_data, 'Longitude':lons_new, 'Latitude':lats_new, 'model': 'nonuc', 'species': species, 'date': month})\n",
    "        interp_IMPROVE_nonuc_df = interp_IMPROVE_nonuc_df.append(tmp_df, sort=False, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, len(interp_IMPROVE_nonuc_df)):\n",
    "    interp_IMPROVE_nonuc_df.loc[i,('date')] = datetime(2016,interp_IMPROVE_nonuc_df['date'][i],calendar.monthrange(2016,interp_IMPROVE_nonuc_df['date'][i])[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a monthly observational dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### EPA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf = geopandas.GeoDataFrame(\n",
    "    EPA_obs_df, geometry=geopandas.points_from_xy(EPA_obs_df.Longitude, EPA_obs_df.Latitude))\n",
    "\n",
    "geometries = gdf['geometry'].apply(lambda x: x.wkt).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPA_obs_df['geometry'] = geometries\n",
    "EPA_obs_df.index = EPA_obs_df['date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "monthly_EPA_df = pd.DataFrame(columns = ['Arithmetic Mean','latitude','longitude', 'geometry','species', 'date'])\n",
    "for geometry in np.unique(geometries):\n",
    "    for species in np.unique(EPA_obs_df['species'].values):\n",
    "        lat = EPA_obs_df.loc[(EPA_obs_df['geometry'] == geometry) & (EPA_obs_df['species'] == species)].groupby(pd.Grouper(freq='M'))['Latitude'].first().values\n",
    "        lon = EPA_obs_df.loc[(EPA_obs_df['geometry'] == geometry) & (EPA_obs_df['species'] == species)].groupby(pd.Grouper(freq='M'))['Longitude'].first().values\n",
    "        data = EPA_obs_df.loc[(EPA_obs_df['geometry'] == geometry) & (EPA_obs_df['species'] == species)].groupby(pd.Grouper(freq='M'))['Arithmetic Mean'].mean()\n",
    "        tmp_df = pd.DataFrame({'Arithmetic Mean': data.values, 'latitude':lat, 'longitude':lon, \n",
    "                               'geometry':geometry, 'species': species, 'date': data.index})\n",
    "        monthly_EPA_df = monthly_EPA_df.append(tmp_df, sort=False, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### IMPROVE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf = geopandas.GeoDataFrame(\n",
    "    IMPROVE_df, geometry=geopandas.points_from_xy(IMPROVE_df.Longitude, IMPROVE_df.Latitude))\n",
    "\n",
    "geometries = gdf['geometry'].apply(lambda x: x.wkt).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMPROVE_df['geometry'] = geometries\n",
    "IMPROVE_df.index = IMPROVE_df['Date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "monthly_IMPROVE_df = pd.DataFrame(columns = ['Arithmetic Mean','latitude','longitude', 'geometry','species', 'date'])\n",
    "for geometry in np.unique(geometries):\n",
    "    for species in np.unique(IMPROVE_df['species'].values):\n",
    "        lat = IMPROVE_df.loc[(IMPROVE_df['geometry'] == geometry) & (IMPROVE_df['species'] == species)].groupby(pd.Grouper(freq='M'))['Latitude'].first().values\n",
    "        lon = IMPROVE_df.loc[(IMPROVE_df['geometry'] == geometry) & (IMPROVE_df['species'] == species)].groupby(pd.Grouper(freq='M'))['Longitude'].first().values\n",
    "        data = IMPROVE_df.loc[(IMPROVE_df['geometry'] == geometry) & (IMPROVE_df['species'] == species)].groupby(pd.Grouper(freq='M'))['Arithmetic Mean'].mean()\n",
    "        tmp_df = pd.DataFrame({'Arithmetic Mean': data.values, 'latitude':lat, 'longitude':lon, \n",
    "                               'geometry':geometry, 'species': species, 'date': data.index})\n",
    "        monthly_IMPROVE_df = monthly_IMPROVE_df.append(tmp_df, sort=False, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add Region Names to the dataframes and save out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add region to the dataframes based on lat_lon dictionary\n",
    "\n",
    "IMPROVE_df['Region'] = 'a'\n",
    "interp_IMPROVE_df['Region'] = 'a'\n",
    "interp_EPA_df['Region'] = 'a'\n",
    "EPA_obs_df['Region'] = 'a'\n",
    "monthly_EPA_df['Region'] = 'a'\n",
    "monthly_IMPROVE_df['Region'] = 'a'\n",
    "interp_IMPROVE_nonuc_df['Region'] = 'a'\n",
    "\n",
    "for region in ['SE_lat_lon','NW_lat_lon','NE_lat_lon','MW_lat_lon','SW_lat_lon']: \n",
    "\n",
    "    IMPROVE_df.loc[\n",
    "            (IMPROVE_df['Longitude'].between(utils.lat_lon_dict[region][0], utils.lat_lon_dict[region][1], inclusive = True)) & (IMPROVE_df['Latitude'].between(utils.lat_lon_dict[region][2], utils.lat_lon_dict[region][3], inclusive = True)), 'Region'] = region\n",
    "    interp_IMPROVE_df.loc[\n",
    "            (interp_IMPROVE_df['Longitude'].between(utils.lat_lon_dict[region][0], utils.lat_lon_dict[region][1], inclusive = True)) & (interp_IMPROVE_df['Latitude'].between(utils.lat_lon_dict[region][2], utils.lat_lon_dict[region][3], inclusive = True)), 'Region'] = region\n",
    "\n",
    "    EPA_obs_df.loc[\n",
    "        (EPA_obs_df['Longitude'].between(utils.lat_lon_dict[region][0], utils.lat_lon_dict[region][1], inclusive = True)) & (EPA_obs_df['Latitude'].between(utils.lat_lon_dict[region][2], utils.lat_lon_dict[region][3], inclusive = True)), 'Region'] = region\n",
    "    interp_df.loc[\n",
    "        (interp_df['Longitude'].between(utils.lat_lon_dict[region][0], utils.lat_lon_dict[region][1], inclusive = True)) & (interp_df['Latitude'].between(utils.lat_lon_dict[region][2], utils.lat_lon_dict[region][3], inclusive = True)), 'Region'] = region\n",
    "    monthly_EPA_df.loc[\n",
    "        (monthly_EPA_df['longitude'].between(utils.lat_lon_dict[region][0], utils.lat_lon_dict[region][1], inclusive = True)) & (monthly_EPA_df['latitude'].between(utils.lat_lon_dict[region][2], utils.lat_lon_dict[region][3], inclusive = True)), 'Region'] = region\n",
    "\n",
    "    monthly_IMPROVE_df.loc[\n",
    "            (monthly_IMPROVE_df['longitude'].between(utils.lat_lon_dict[region][0], utils.lat_lon_dict[region][1], inclusive = True)) & (monthly_IMPROVE_df['latitude'].between(utils.lat_lon_dict[region][2], utils.lat_lon_dict[region][3], inclusive = True)), 'Region'] = region\n",
    "\n",
    "    interp_IMPROVE_nonuc_df.loc[\n",
    "            (interp_IMPROVE_nonuc_df['Longitude'].between(utils.lat_lon_dict[region][0], utils.lat_lon_dict[region][1], inclusive = True)) & (interp_IMPROVE_nonuc_df['Latitude'].between(utils.lat_lon_dict[region][2], utils.lat_lon_dict[region][3], inclusive = True)), 'Region'] = region\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "interp_EPA_nonuc_df['Region'] = 'a'\n",
    "for region in ['SE_lat_lon','NW_lat_lon','NE_lat_lon','MW_lat_lon','SW_lat_lon']: \n",
    "\n",
    "    interp_EPA_nonuc_df.loc[\n",
    "                (interp_EPA_nonuc_df['Longitude'].between(utils.lat_lon_dict[region][0], utils.lat_lon_dict[region][1], inclusive = True)) & (interp_EPA_nonuc_df['Latitude'].between(utils.lat_lon_dict[region][2], utils.lat_lon_dict[region][3], inclusive = True)), 'Region'] = region\n",
    "interp_EPA_nonuc_df.to_csv('interp_EPA_nonuc_df.csv', date_format='%Y%m%d', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "interp_EPA_df.to_csv('interp_EPA_df.csv', date_format='%Y%m%d', index=False)\n",
    "EPA_obs_df.to_csv('EPA_obs_df.csv', date_format='%Y%m%d', index=False)\n",
    "monthly_EPA_df.to_csv('EPA_monthly_obs_df.csv', date_format='%Y%m%d', index=False)\n",
    "IMPROVE_df.to_csv('IMPROVE_df.csv', date_format='%Y%m%d', index=False)\n",
    "interp_IMPROVE_df.to_csv('interp_IMPROVE_df.csv', date_format='%Y%m%d', index=False)\n",
    "monthly_IMPROVE_df.to_csv('IMPROVE_monthly_obs_df.csv', date_format='%Y%m%d', index=False)\n",
    "interp_IMPROVE_nonuc_df.to_csv('interp_IMPROVE_nonuc_df.csv', date_format='%Y%m%d', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
