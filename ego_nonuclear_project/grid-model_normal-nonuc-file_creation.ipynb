{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import xarray as xr\n",
    "\n",
    "import regionmask\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import cartopy.crs as ccrs\n",
    "from matplotlib import cm\n",
    "from matplotlib.colors import ListedColormap, LinearSegmentedColormap\n",
    "import cartopy.feature as cfeat\n",
    "import matplotlib.patches as mpatches\n",
    "import datetime\n",
    "\n",
    "import feather\n",
    "\n",
    "import glob\n",
    "\n",
    "\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "import utils\n",
    "import plotting\n",
    "\n",
    "np.seterr(invalid='ignore'); # disable a warning from matplotlib and cartopy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Concentration Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_normal_model = utils.import_GC_runs_general('../../GCrundirs/type_NA-out_conc-yr_2016-gridmod_final-validation/OutputDir/','GEOSChem.SpeciesConc.2016*_0000z.nc4','GEOSChem.AerosolMass.2016*_0000z.nc4','normal_model' )\n",
    "ds_nonuc_model = utils.import_GC_runs_general('../../GCrundirs/type_NA-out_conc-yr_2016-gridmod_nonuclear/OutputDir/','GEOSChem.SpeciesConc.2016*_0000z.nc4','GEOSChem.AerosolMass.2016*_0000z.nc4','nonuc_model' )\n",
    "\n",
    "datasets = [\n",
    "    ds_normal_model,\n",
    "    ds_nonuc_model\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "poll_ds = utils.combine_and_convert_ds(utils.gas_species_list, utils.aerosol_species_dict.keys(),\n",
    "                                       datasets,['normal_model', 'nonuc_model'], \n",
    "                                       ['nonuc_model'], \n",
    "                                       'normal_model', \n",
    "                                       'normal and nonuclear' )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<xarray.backends.zarr.ZarrStore at 0x7f26ca3eb620>"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "poll_ds.to_zarr('./data/nonuc_normal_GC.zarr', mode = 'w') #save the dataset "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HEMCO Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_normal = xr.open_mfdataset('../../GCrundirs/type_NA-out_conc-yr_2016-gridmod_final-validation/OutputDir/HEMCO_diagnostics.2016*.nc', combine = 'by_coords')\n",
    "ds_nonuc = xr.open_mfdataset('../../GCrundirs/type_NA-out_conc-yr_2016-gridmod_nonuclear/OutputDir/HEMCO_diagnostics.2016*.nc', combine = 'by_coords')\n",
    "\n",
    "ds_normal = ds_normal.isel(lev = 0)\n",
    "ds_nonuc = ds_nonuc.isel(lev = 0)\n",
    "\n",
    "ds_emis = xr.concat([ds_nonuc, ds_normal], pd.Index(['nonuc', 'normal'], name='model_name'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "emis_list = ['EmisNO2_Anthro', 'EmisNO_Anthro', 'EmisSO2_Anthro',  'EmisNH3_Total']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "emis_ds = ds_emis.drop_vars([species for species in ds_emis.data_vars if species not in emis_list])\n",
    "emis_ds['EmisNOx_Anthro'] = (\n",
    "        emis_ds['EmisNO2_Anthro'] + emis_ds['EmisNO_Anthro'] #sum our NO2 and NO to get NOx\n",
    "                   )\n",
    "emis_ds['EmisNOx_Anthro'].attrs['units'] = 'kg/m2/s'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<xarray.backends.zarr.ZarrStore at 0x7f647a315f10>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emis_ds.to_zarr('./data/emissions_HEMCO', mode = 'w') #save the dataset "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# US-EGO Emissions Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### import files and change hydro #####\n",
    "\n",
    "###get ORIS, plant type, and Region Name from our modified generation file\n",
    "oris_nonuc_df = pd.read_csv('../optimization_model/good_model_inputs/inputs_gen_no-nuclear_all-generators_20k-new_name.csv',usecols=[1,2,4,5,8,22,23,24,25])\n",
    "oris_normal_df = pd.read_csv('../optimization_model/good_model_inputs/inputs_gen_normal.csv',usecols=[1,2,4,5,8,22,23,24,25])\n",
    "oris_nonuc_df.loc[oris_nonuc_df['FuelType'] == 'Pumps', 'FuelType'] = 'Hydro' #change pumps to hydro label\n",
    "oris_normal_df.loc[oris_normal_df['FuelType'] == 'Pumps', 'FuelType'] = 'Hydro' #change pumps to hydro label\n",
    "\n",
    "###import egrid generation data and modify the index to be ORISCode\n",
    "egrid_df_raw = pd.read_excel('../raw_data/egrid2016_data.xlsx',sheet_name='GEN16', usecols='D, J, L')\n",
    "egrid = egrid_df_raw.drop(egrid_df_raw.index[0]).rename(columns={'DOE/EIA ORIS plant or facility code':'ORISCode'})\n",
    "#change those with no capacity to 1 (so that our capacity factor calculation doesn't fail)\n",
    "egrid.loc[egrid['Generator nameplate capacity (MW)'] == 0, 'Generator nameplate capacity (MW)'] = 1\n",
    "#calculate the capacity factor of generation in egrid\n",
    "egrid['egrid_capafactor'] = egrid['Generator annual net generation (MWh)'] / (8760 * egrid['Generator nameplate capacity (MW)']) \n",
    "\n",
    "###import the generation data from our optimization\n",
    "gen_normal_df=feather.read_dataframe('../optimization_model/outputs/gen_normal.feather')\n",
    "\n",
    "###import the generation data from our optimization\n",
    "gen_nonuc_df=feather.read_dataframe('../optimization_model/outputs/gen_no-nuclear_modified-all-generators.feather')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### change index and convert to xarray #####\n",
    "\n",
    "#group by ORIS code and make a date and ORIS code mult index\n",
    "gen_nonuc_df = pd.concat([gen_nonuc_df,oris_nonuc_df['ORISCode']], axis = 1).groupby(['ORISCode']).sum()\n",
    "gen_normal_df = pd.concat([gen_normal_df,oris_normal_df['ORISCode']], axis = 1).groupby(['ORISCode']).sum()\n",
    "gen_normal_df = gen_normal_df.stack()\n",
    "gen_nonuc_df = gen_nonuc_df.stack()\n",
    "gen_nonuc_df.index.names = (['ORISCode','date'])\n",
    "gen_normal_df.index.names = (['ORISCode','date'])\n",
    "\n",
    "egrid = egrid.groupby('ORISCode').sum().drop(columns = 'egrid_capafactor') #drop capacity factor because that isn't the sum\n",
    " \n",
    "#convert to xarray datasets\n",
    "oris_nonuc_ds = oris_nonuc_df.to_xarray()\n",
    "oris_normal_ds = oris_normal_df.to_xarray()\n",
    "egrid_ds = egrid.to_xarray()\n",
    "gen_normal_ds = gen_normal_df.to_xarray()\n",
    "gen_nonuc_ds = gen_nonuc_df.to_xarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_egrid_generation(oris_ds, gen_ds, egrid_ds):   \n",
    "    #create a capacity, fueltype, and regionname grouped by ORISCode\n",
    "    capacity = oris_ds.groupby('ORISCode').sum()['Capacity']\n",
    "    fueltype = oris_ds.to_dataframe().groupby('ORISCode').first()['FuelType']\n",
    "    regionname = oris_ds.to_dataframe().groupby('ORISCode').first()['RegionName']\n",
    "    #group by ORIS code and take the mean of everything but capacity\n",
    "    oris_ds = oris_ds.groupby('ORISCode').mean().drop('Capacity')\n",
    "    #rename our generation variable\n",
    "    gen_ds = gen_ds.rename('modelgeneration')\n",
    "\n",
    "    ###concatenate the generation and ORIS files\n",
    "    gmodel_oris_ds = xr.merge([gen_ds, oris_ds])\n",
    "    #add in the capacity\n",
    "    gmodel_oris_ds['Capacity'] = capacity\n",
    "    #create a column for capacity factors\n",
    "    gmodel_oris_ds['model_capafactor'] = 100 * gmodel_oris_ds['modelgeneration'] / (gmodel_oris_ds['Capacity'] * 8760) # % generation for each year's total capacity\n",
    "    \n",
    "    ###concatenate our model/oris and egrid emissions dataframes into one, grouped by ORIS code\n",
    "    gmodel_egrid_ds = xr.merge([gmodel_oris_ds, egrid_ds])\n",
    "    #turn all zeroes (just in the modelgeneration) to NAN\n",
    "    gmodel_egrid_ds.where('modelgeneration' == 0)['modelgeneration'] = np.nan\n",
    "    #rename the egrid data column for ease\n",
    "    gmodel_egrid_ds = gmodel_egrid_ds.rename({'Generator annual net generation (MWh)':'annual_egridgeneration'})\n",
    "    #add in fueltype\n",
    "    gmodel_egrid_ds['fueltype'] = fueltype\n",
    "    gmodel_egrid_ds = gmodel_egrid_ds.set_coords('fueltype')\n",
    "    #add in region name\n",
    "    gmodel_egrid_ds['regionname'] = regionname\n",
    "    gmodel_egrid_ds = gmodel_egrid_ds.set_coords('regionname')\n",
    "    return(gmodel_egrid_ds)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/emfreese/anaconda3/envs/grid_model/lib/python3.8/site-packages/xarray/core/nanops.py:142: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis=axis, dtype=dtype)\n"
     ]
    }
   ],
   "source": [
    "#### combine ourr egrid and generation info for no nuclear and normal models ####\n",
    "nonuc_gmodel_egrid_ds = combine_egrid_generation(oris_nonuc_ds, gen_nonuc_ds, egrid_ds)\n",
    "normal_gmodel_egrid_ds = combine_egrid_generation(oris_normal_ds, gen_normal_ds, egrid_ds)\n",
    "gmodel_egrid_raw_ds = xr.concat([nonuc_gmodel_egrid_ds, normal_gmodel_egrid_ds], pd.Index(['nonuc','normal'], name='model_name'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### fix datetime and add dec 31st at the 23rd hour ####\n",
    "\n",
    "###create a dict for dec 31st 23rd hour (just copy the dec 31 22nd hour data over)\n",
    "for name in models:\n",
    "    dec23_ds = gmodel_egrid_raw_ds.copy().isel(date = [-1])\n",
    "    #change date to datetime for the 23rd hour\n",
    "    dec23_ds['date'] = [datetime.datetime(2017,12,31,23,0)]\n",
    "    \n",
    "###change all dates to datetime\n",
    "#make a list of dates for the year\n",
    "base = datetime.datetime(2017, 1, 1) #base date\n",
    "date_list = [base + datetime.timedelta(hours=x) for x in range(8759)] #loop through all hours but the final one (we will add it in above)\n",
    "date_list\n",
    "for name in models:\n",
    "    gmodel_egrid_raw_ds['date'] = date_list\n",
    "    gmodel_egrid_ds = xr.merge([gmodel_egrid_raw_ds, dec23_ds])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note:\n",
    "\n",
    "To convert our generation in MWh to get the emissions in kg/sec, we use the following (and making sure our emissions rates are in kg/sec)\n",
    "\n",
    "$MWH/3600sec -> (MW/s) * kg/MW -> kg/s$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/emfreese/anaconda3/envs/grid_model/lib/python3.8/site-packages/xarray/core/common.py:671: FutureWarning: This DataArray contains multi-dimensional coordinates. In the future, the dimension order of these coordinates will be restored as well unless you specify restore_coord_dims=False.\n",
      "  return self._groupby_cls(\n"
     ]
    }
   ],
   "source": [
    "###### add NOx, SO2, CO2, CH4 emissions to gmodel_egrid dataset ######\n",
    "\n",
    "no_mult = 0.8544304 # NO/NOx as estimated from NEI2011 inventory\n",
    "no2_mult = 1 - 0.8544304 # NO2/NOx as estimated from NEI2011 inventory\n",
    "\n",
    "### process our emissions by multiplying generation* emissions factors\n",
    "gmodel_egrid_ds['model_NO_rate']  = no_mult * gmodel_egrid_ds['modelgeneration']/3600 * gmodel_egrid_ds['PLNOXRTA']\n",
    "gmodel_egrid_ds['model_NO2_rate']  = no2_mult * gmodel_egrid_ds['modelgeneration']/3600 * gmodel_egrid_ds['PLNOXRTA']\n",
    "gmodel_egrid_ds['model_SO2_rate']  =  gmodel_egrid_ds['modelgeneration']/3600 * gmodel_egrid_ds['PLSO2RTA']\n",
    "gmodel_egrid_ds['model_CO2_rate']  =  gmodel_egrid_ds['modelgeneration']/3600 * gmodel_egrid_ds['PLCO2RTA']\n",
    "gmodel_egrid_ds['model_CH4_rate']  =  gmodel_egrid_ds['modelgeneration']/3600 * gmodel_egrid_ds['PLCH4RTA']\n",
    "\n",
    "gmodel_egrid_ds['egrid_annual_NO_rate']  = no_mult * gmodel_egrid_ds['annual_egridgeneration']/3600 * gmodel_egrid_ds['PLNOXRTA']\n",
    "gmodel_egrid_ds['egrid_annual_NO2_rate']  = no2_mult * gmodel_egrid_ds['annual_egridgeneration']/3600 * gmodel_egrid_ds['PLNOXRTA']\n",
    "gmodel_egrid_ds['egrid_annual_SO2_rate']  =  gmodel_egrid_ds['annual_egridgeneration']/3600 * gmodel_egrid_ds['PLSO2RTA']\n",
    "gmodel_egrid_ds['egrid_annual_CO2_rate']  =  gmodel_egrid_ds['annual_egridgeneration']/3600 * gmodel_egrid_ds['PLCO2RTA']\n",
    "gmodel_egrid_ds['egrid_annual_CH4_rate']  =  gmodel_egrid_ds['annual_egridgeneration']/3600 * gmodel_egrid_ds['PLCH4RTA']\n",
    "\n",
    "##### annual generation in original dataset ######\n",
    "gmodel_egrid_ds['annual_modelgeneration'] = gmodel_egrid_ds['modelgeneration'].groupby('ORISCode').sum(dim = 'date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "####### create new datasets for region and fuel type grouped data, add annual generation to normal ds ######\n",
    "\n",
    "###list of pollutants\n",
    "pollutants = ['NO','NO2','SO2','CO2','CH4']\n",
    "\n",
    "def create_grouped_ds(grouper, model):\n",
    "    grouped_ds = gmodel_egrid_ds.copy().sel(model_name = model).groupby(grouper).sum()\n",
    "    grouped_ds = grouped_ds.drop(['model_capafactor','PLCH4RTA','PLCO2RTA','PLNOXRTA','PLSO2RTA','PLN2ORTA'])\n",
    "    return(grouped_ds)\n",
    "\n",
    "###create datasets of grouped fuel type and region name, combine\n",
    "nonuc_fueltype_grouped_ds = create_grouped_ds('fueltype', 'nonuc')\n",
    "normal_fueltype_grouped_ds = create_grouped_ds('fueltype', 'normal')\n",
    "\n",
    "nonuc_regionname_grouped_ds = create_grouped_ds('regionname', 'nonuc')\n",
    "normal_regionname_grouped_ds = create_grouped_ds('regionname', 'normal')\n",
    "\n",
    "fueltype_grouped_ds = xr.concat([nonuc_fueltype_grouped_ds, normal_fueltype_grouped_ds], pd.Index(['nonuc','normal'], name='model_name'))\n",
    "regionname_grouped_ds = xr.concat([nonuc_regionname_grouped_ds, normal_regionname_grouped_ds], pd.Index(['nonuc','normal'], name='model_name'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add annual emissions of each pollutant\n",
    "for pollutant in pollutants:\n",
    "    regionname_grouped_ds[f'model_annual_{pollutant}_conc'] = (regionname_grouped_ds[f'model_{pollutant}_rate']*86400).sum(dim = 'date')\n",
    "    fueltype_grouped_ds[f'model_annual_{pollutant}_conc'] = (fueltype_grouped_ds[f'model_{pollutant}_rate']*86400).sum(dim = 'date')\n",
    "    gmodel_egrid_ds[f'model_annual_{pollutant}_conc'] = (gmodel_egrid_ds[f'model_{pollutant}_rate']*86400).sum(dim = 'date')\n",
    "\n",
    "    regionname_grouped_ds[f'egrid_annual_{pollutant}_conc'] = (regionname_grouped_ds[f'egrid_annual_{pollutant}_rate']*86400*365)\n",
    "    fueltype_grouped_ds[f'egrid_annual_{pollutant}_conc'] = (fueltype_grouped_ds[f'egrid_annual_{pollutant}_rate']*86400*365)\n",
    "    gmodel_egrid_ds[f'egrid_annual_{pollutant}_conc'] = (gmodel_egrid_ds[f'egrid_annual_{pollutant}_rate']*86400*365)\n",
    "\n",
    "#add ratio of difference in emissions normal-nonuc/ difference in generation normal-nonuc to the nonuc dataset\n",
    "for pollutant in pollutants:\n",
    "    fueltype_grouped_ds.sel(model_name = 'nonuc')[f'normal-nonuc_{pollutant}-gen_ratio'] = (fueltype_grouped_ds.sel(model_name = 'normal')[f'model_annual_{pollutant}_conc']-\n",
    "                                                                       fueltype_grouped_ds.sel(model_name = 'nonuc')[f'model_annual_{pollutant}_conc'])/(fueltype_grouped_ds.sel(model_name = 'normal')['annual_modelgeneration']-\n",
    "                                                                                                                             fueltype_grouped_ds.sel(model_name = 'nonuc')['annual_modelgeneration'])\n",
    "    regionname_grouped_ds.sel(model_name = 'nonuc')[f'normal-nonuc_{pollutant}-gen_ratio'] = (regionname_grouped_ds.sel(model_name = 'normal')[f'model_annual_{pollutant}_conc']-\n",
    "                                                                         regionname_grouped_ds.sel(model_name = 'nonuc')[f'model_annual_{pollutant}_conc'])/(regionname_grouped_ds.sel(model_name = 'normal')['annual_modelgeneration']-\n",
    "                                                                                                                                 regionname_grouped_ds.sel(model_name = 'nonuc')['annual_modelgeneration'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### add attributes ####\n",
    "for pollutant in pollutants:\n",
    "    if pollutant == 'NO2' or 'NO':\n",
    "                gmodel_egrid_ds[f'PLNOXRTA'].attrs['units'] = 'kg/Mwh'\n",
    "    else:\n",
    "        gmodel_egrid_ds[f'PL{pollutant}RTA'].attrs['units'] = 'kg/Mwh'\n",
    "    for idx, ds in enumerate([regionname_grouped_ds, fueltype_grouped_ds, gmodel_egrid_ds]):\n",
    "        ds[f'model_{pollutant}_rate'].attrs['units'] = 'kg/s'\n",
    "        ds[f'modelgeneration'].attrs['units'] = 'Mwh'\n",
    "        for typem in ['egrid','model']:\n",
    "            ds[f'annual_{typem}generation'].attrs['units'] = 'Mwh'\n",
    "            ds[f'{typem}_annual_{pollutant}_conc'].attrs['units'] = 'kg/yr'\n",
    "        ds.attrs['model'] = name\n",
    "        ds.attrs['group'] = ['Region','Fuel Type','All'][idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### save datasets #####\n",
    "\n",
    "### Final datasets to save are: gmodel_egrid, fueltype_grouped_ds, regionname_grouped_ds\n",
    "regionname_grouped_ds.to_netcdf(f'./data/regionname_grouped_emissions_ds.nc', 'w')\n",
    "fueltype_grouped_ds.to_netcdf(f'./data/fueltype_grouped_emissions_ds.nc', 'w')\n",
    "gmodel_egrid_ds.to_netcdf(f'./data/gmodel_egrid_emissions_ds.nc', 'w')\n",
    "\n",
    "### datasets partway to save are:\n",
    "\n",
    "oris_nonuc_ds.to_netcdf('../optimization_model/outputs/oris_nonuc_ds.nc', 'w')\n",
    "oris_normal_ds.to_netcdf('../optimization_model/outputs/oris_normal_ds.nc', 'w')\n",
    "egrid_ds.to_netcdf('../optimization_model/outputs/egrid_ds.nc', 'w')\n",
    "gen_normal_ds.to_netcdf('../optimization_model/outputs/gen_normal_ds.nc', 'w')\n",
    "gen_nonuc_ds.to_netcdf('../optimization_model/outputs/gen_nonuc_ds.nc', 'w')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MERRA2 RH and T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### import MERRA2 datasets for RH and T #####\n",
    "\n",
    "#import \n",
    "T_ds = xr.open_mfdataset('../../MERRA2/2016/GEOS_0.5x0.625_NA/MERRA2/2016/*/MERRA2.2016*.A1.05x0625.NA.nc4', combine = 'by_coords')\n",
    "RH_ds = xr.open_mfdataset('../../MERRA2/2016/GEOS_0.5x0.625_NA/MERRA2/2016/*/MERRA2.2016*.A3dyn.05x0625.NA.nc4', combine = 'by_coords')\n",
    "\n",
    "#reduce datasets just to T and RH\n",
    "T_ds = T_ds['TS']\n",
    "RH_ds = RH_ds['RH']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Select T and RH in the bounds of our US lat and lon #####\n",
    "T = {}\n",
    "RH = {}\n",
    "for region in utils.lat_lon_dict.keys():\n",
    "    T[region] = {}\n",
    "    T[region] = T_ds.sel(\n",
    "        lon = slice(utils.lat_lon_dict[region][0], utils.lat_lon_dict[region][1]), \n",
    "        lat = slice(utils.lat_lon_dict[region][2],utils.lat_lon_dict[region][3])\n",
    "    ).groupby('time.season').mean()\n",
    "    RH[region] = {}\n",
    "    RH[region] = RH_ds.sel(\n",
    "        lon = slice(utils.lat_lon_dict[region][0], utils.lat_lon_dict[region][1]), \n",
    "        lat = slice(utils.lat_lon_dict[region][2],utils.lat_lon_dict[region][3])\n",
    "    ).groupby('time.season').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Calculate seasonal mean RH and T by region #####\n",
    "T_seasonal_mean = {}\n",
    "RH_seasonal_mean = {}\n",
    "for region in utils.lat_lon_dict.keys():\n",
    "    T_seasonal_mean[region] = {}\n",
    "    RH_seasonal_mean[region] = {}\n",
    "    for seasons in ['DJF','JJA','MAM','SON']:\n",
    "        T_seasonal_mean[region][seasons] = T[region].sel(season = seasons).mean().values\n",
    "        RH_seasonal_mean[region][seasons] = RH[region].sel(season = seasons).mean().values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### convert to dataframes ##### \n",
    "\n",
    "T_df = pd.DataFrame.from_dict({(i,j): T_seasonal_mean[i][j]\n",
    "                            for i in T_seasonal_mean.keys() \n",
    "                            for j in T_seasonal_mean[i].keys()},\n",
    "                            orient='index', columns = ['T'])\n",
    "T_df.index = pd.MultiIndex.from_tuples(T_df.index)\n",
    "\n",
    "RH_df = pd.DataFrame.from_dict({(i,j): RH_seasonal_mean[i][j]\n",
    "                            for i in RH_seasonal_mean.keys() \n",
    "                            for j in RH_seasonal_mean[i].keys()},\n",
    "                            orient='index', columns = ['RH'])\n",
    "RH_df.index = pd.MultiIndex.from_tuples(RH_df.index)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### merge dataframes #####\n",
    "RH_T_df = pd.merge(\n",
    "    T_df, RH_df, \n",
    "    left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### save dataframe #####\n",
    "pd.DataFrame.to_csv(RH_T_df, './data/RH_T.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ISORROPIA Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "group not found at path ''",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-bddf29ce12ae>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#import HEMCO emissions files and choose the first level, combine into one dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mds_nonuc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen_zarr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./pm_nonuc_ds.zarr'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mds_normal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen_zarr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../model_validation/pm_ds.zarr'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mds_normal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mds_normal\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'MODEL'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'model_name'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mds_nonuc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mds_normal\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIndex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'no_nuclear'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'normal'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'model_name'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/conda_env/lib/python3.7/site-packages/xarray/backends/zarr.py\u001b[0m in \u001b[0;36mopen_zarr\u001b[0;34m(store, group, synchronizer, chunks, decode_cf, mask_and_scale, decode_times, concat_characters, decode_coords, drop_variables, consolidated, overwrite_encoded_chunks, **kwargs)\u001b[0m\n\u001b[1;32m    595\u001b[0m         \u001b[0msynchronizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msynchronizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    596\u001b[0m         \u001b[0mgroup\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 597\u001b[0;31m         \u001b[0mconsolidated\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconsolidated\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    598\u001b[0m     )\n\u001b[1;32m    599\u001b[0m     \u001b[0mds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmaybe_decode_store\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzarr_store\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/conda_env/lib/python3.7/site-packages/xarray/backends/zarr.py\u001b[0m in \u001b[0;36mopen_group\u001b[0;34m(cls, store, mode, synchronizer, group, consolidated, consolidate_on_close)\u001b[0m\n\u001b[1;32m    259\u001b[0m             \u001b[0mzarr_group\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzarr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen_consolidated\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstore\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mopen_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    260\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 261\u001b[0;31m             \u001b[0mzarr_group\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzarr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen_group\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstore\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mopen_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    262\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzarr_group\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconsolidate_on_close\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/conda_env/lib/python3.7/site-packages/zarr/hierarchy.py\u001b[0m in \u001b[0;36mopen_group\u001b[0;34m(store, mode, cache_attrs, synchronizer, path, chunk_store)\u001b[0m\n\u001b[1;32m   1144\u001b[0m             \u001b[0merr_contains_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1145\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcontains_group\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstore\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1146\u001b[0;31m             \u001b[0merr_group_not_found\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1147\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1148\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'w'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/conda_env/lib/python3.7/site-packages/zarr/errors.py\u001b[0m in \u001b[0;36merr_group_not_found\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0merr_group_not_found\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'group not found at path %r'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: group not found at path ''"
     ]
    }
   ],
   "source": [
    "#import HEMCO emissions files and choose the first level, combine into one dataset\n",
    "ds_nonuc = xr.open_zarr('./data/pm_nonuc_ds.zarr')\n",
    "ds_normal = xr.open_zarr('../model_validation/data/pm_ds.zarr')\n",
    "ds_normal = ds_normal.sel(model_name = 'MODEL').drop('model_name')\n",
    "ds = xr.concat([ds_nonuc, ds_normal], pd.Index(['no_nuclear', 'normal'], name='model_name'))\n",
    "\n",
    "#import RH and T dataframe\n",
    "RH_T_df = pd.read_csv('./data/RH_T.csv', index_col=[0,1])\n",
    "\n",
    "#subset our ds into just the species we need\n",
    "species_list = ['SO4','NH3','HNO3','NIT','NH4']\n",
    "isorropia_ds = ds[species_list]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SO4, NH3, NO3, Cl, Ca, K, Mg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a dataframe for our isorropia monthly mean values for no nuclear and normal cases, indexed by species, location, season\n",
    "\n",
    "isorropia_dict = {}\n",
    "for species in species_list:\n",
    "    isorropia_dict[species]= {}\n",
    "    for region in utils.lat_lon_dict.keys():\n",
    "        isorropia_dict[species][region] = {}\n",
    "        for season in ['DJF','MAM','JJA','SON']:\n",
    "            data = isorropia_ds.sel(lon = slice(utils.lat_lon_dict[region][0], utils.lat_lon_dict[region][1]), \n",
    "                                    lat = slice(utils.lat_lon_dict[region][2],utils.lat_lon_dict[region][3])).groupby('time.season').mean(dim = ['lat','lon','time']).sel(season = season)[species]\n",
    "            isorropia_dict[species][region][season] = data.values\n",
    "            \n",
    "isorropia_df = pd.DataFrame.from_dict({(i,j,k): isorropia_dict[i][j][k] \n",
    "                            for i in isorropia_dict.keys() \n",
    "                            for j in isorropia_dict[i].keys()\n",
    "                            for k in isorropia_dict[i][j].keys()},\n",
    "                            orient='index', columns = ['no_nuclear','normal'])\n",
    "\n",
    "isorropia_df.index = pd.MultiIndex.from_tuples(isorropia_df.index, names = ['Species','Location', 'Season'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/emfreese/anaconda3/envs/conda_env/lib/python3.7/site-packages/ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "/home/emfreese/anaconda3/envs/conda_env/lib/python3.7/site-packages/ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "#convert from mol/mol to mol/m3 by multiplying by P/T*R (mol/m3)\n",
    "stp_p = 101325 #Pa = kg/m/s^2\n",
    "R = 8.314 #J/K/mol\n",
    "isorropia_df['no_nuclear_2x'] = '0'\n",
    "for species in species_list:\n",
    "    for region in utils.lat_lon_dict.keys():\n",
    "            for season in ['DJF','MAM','JJA','SON']:\n",
    "                isorropia_df.loc[(species,region,season)]['no_nuclear'] *= stp_p/R/RH_T_df.loc[(region,season)]['T']\n",
    "                isorropia_df.loc[(species,region,season)]['normal'] *= stp_p/R/RH_T_df.loc[(region,season)]['T']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate the total Nitrate and ammonium by molarity\n",
    "isorropia_df_TNO3 = isorropia_df.loc['HNO3'] + isorropia_df.loc['NIT'] \n",
    "isorropia_df_TNH3 = isorropia_df.loc['NH3'] + isorropia_df.loc['NH4'] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run through ISORROPIA\n",
    "### Only run once to initiate a new ISORROPIA output, otherwise, the output is already made"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "os.chdir('../../ISORROPIAIIStandalone')\n",
    "for model in ['no_nuclear', 'normal']:\n",
    "    for region in ['SE_lat_lon', 'NW_lat_lon', 'NE_lat_lon', 'MW_lat_lon', 'SW_lat_lon']:\n",
    "            for season in ['DJF','JJA']:\n",
    "                T_tmp = RH_T_df.loc[(region, season)]['T']\n",
    "                RH_tmp = RH_T_df.loc[(region, season)]['RH']\n",
    "                SO4_tmp = isorropia_df.loc['SO4',region,season][model]\n",
    "                \n",
    "                os.system(f'mkdir -p {region}_{season}_{model}/')\n",
    "                os.system(f'cp src/* {region}_{season}_{model}/')\n",
    "                \n",
    "                os.chdir(f'{region}_{season}_{model}/')\n",
    "                print(os.listdir())\n",
    "                \n",
    "                cmdprefix = 'cat ISORange.dat | sed -i '\n",
    "                cmdT = f\"-e 's/T(K):       0.0/T(K):       {T_tmp}/' \"\n",
    "                cmdRH = f\"-e 's/RH(-):      0.0/RH(-):      {RH_tmp}/' \"\n",
    "                cmdNH3 = f\"-e 's/TSO4:       0.0e-9/TSO4:       {SO4_tmp}/' \"\n",
    "                cmdoutput = f\"-e 's/Output:     NW_DJF_nonuc_ISOOutput.nc/Output:     ISOOutput_{region}_{season}_{model}_constant_SO4.nc/' \"\n",
    "                cmdsuffix = 'ISORange.dat'\n",
    "                \n",
    "                cmd = cmdprefix+cmdT+cmdRH+cmdNH3+cmdoutput+cmdsuffix\n",
    "                \n",
    "                os.system(cmd)\n",
    "                \n",
    "                os.chdir('../')\n",
    "\n",
    "os.chdir('../grid_model/ego_nonuclear_project/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### save our data out ####\n",
    "isorropia_df.to_csv('./data/ISORROPIA_data.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
