{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Bad key \"text.kerning_factor\" on line 4 in\n",
      "/home/emfreese/anaconda3/envs/conda_env/lib/python3.7/site-packages/matplotlib/mpl-data/stylelib/_classic_test_patch.mplstyle.\n",
      "You probably need to get an updated matplotlibrc file from\n",
      "http://github.com/matplotlib/matplotlib/blob/master/matplotlibrc.template\n",
      "or from the matplotlib source distribution\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import xarray as xr\n",
    "\n",
    "import regionmask\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import cartopy.crs as ccrs\n",
    "from matplotlib import cm\n",
    "from matplotlib.colors import ListedColormap, LinearSegmentedColormap\n",
    "import cartopy.feature as cfeat\n",
    "from scipy.interpolate import RectBivariateSpline\n",
    "from datetime import datetime, timedelta\n",
    "import geopandas\n",
    "\n",
    "import calendar\n",
    "\n",
    "import glob\n",
    "\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "import utils\n",
    "\n",
    "np.seterr(invalid='ignore'); # disable a warning from matplotlib and cartopy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GEOS Chem Runs\n",
    "\n",
    "Using egrid, NEI, and our model emissions inventories for NO, NO2, SO2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "egrid_path = '../../GCrundirs/type_NA-out_conc-yr_2016-gridmod_final-validation-egrid/OutputDir/'\n",
    "NEI_path = '../../GCrundirs/type_NA-out_conc-yr_2016-gtropchem/merra2_05x0625_tropchem_na/OutputDir/'\n",
    "MODEL_path = '../../GCrundirs/type_NA-out_conc-yr_2016-gridmod_final-validation/OutputDir/'\n",
    "speciesconc_output = 'GEOSChem.SpeciesConc.2016*.nc4'\n",
    "aerosol_output = 'GEOSChem.AerosolMass.2016*.nc4'\n",
    "\n",
    "ds_egrid, ds_NEI, ds_MODEL = utils.import_GC_runs(egrid_path, NEI_path, MODEL_path, aerosol_output, speciesconc_output)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = [\n",
    "    ds_egrid,\n",
    "    ds_NEI,\n",
    "    ds_MODEL\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = xr.concat(datasets, pd.Index(['egrid', 'NEI', 'MODEL'], name='model_name'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ds' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-0588069ffbc9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mspecies_tracers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'PM25'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m ds['SpeciesConc_NOx'] = (\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0mds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'SpeciesConc_NO'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'SpeciesConc_NO2'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m#sum our NO2 and NO to get NOx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m                    )\n",
      "\u001b[0;31mNameError\u001b[0m: name 'ds' is not defined"
     ]
    }
   ],
   "source": [
    "species_list = [ #create a list of the species we want to keep\n",
    "    'NO',\n",
    "    'NO2',\n",
    "    'SO2',\n",
    "    'O3',\n",
    "    'NOx',\n",
    "]\n",
    "species_tracers = ['SpeciesConc_' + spec for spec in species_list]\n",
    "species_tracers.append('PM25')\n",
    "ds['SpeciesConc_NOx'] = (\n",
    "        ds['SpeciesConc_NO'] + ds['SpeciesConc_NO2'] #sum our NO2 and NO to get NOx\n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "poll_ds = ds[species_tracers].rename({'SpeciesConc_' + spec: spec for spec in species_list})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert everything to ppbv\n",
    "for species in species_list:\n",
    "    poll_ds[f'{species}'] *= 1e9 #convert from mol/mol to ppbv\n",
    "    poll_ds[f'{species}'].attrs['units'] = 'ppbv'\n",
    "\n",
    "\n",
    "for species in species_list:\n",
    "    #calculate the differences for species between model and NEI\n",
    "    poll_ds[f'dif_MODEL-NEI_{species}'] = poll_ds.sel(model_name = 'MODEL')[f'{species}'] - poll_ds.sel(model_name = 'NEI')[f'{species}']\n",
    "    poll_ds[f'dif_MODEL-NEI_{species}'].attrs['units'] = 'ppbv'\n",
    "\n",
    "    #calculate the differences for species between model and egrid\n",
    "    poll_ds[f'dif_MODEL-egrid_{species}'] = poll_ds.sel(model_name = 'MODEL')[f'{species}'] - poll_ds.sel(model_name = 'egrid')[f'{species}']\n",
    "    poll_ds[f'dif_MODEL-egrid_{species}'].attrs['units'] = 'ppbv'\n",
    "\n",
    "#calculate the dif for PM between model and NEI\n",
    "poll_ds['dif_MODEL-NEI_PM25'] = poll_ds.sel(model_name = 'MODEL')['PM25']- poll_ds.sel(model_name = 'NEI')['PM25']\n",
    "poll_ds[f'dif_MODEL-NEI_PM25'].attrs['units'] = 'PM $\\mu$g m$^{-3}$'\n",
    "\n",
    "#calculate the dif for PM between model and NEI\n",
    "poll_ds['dif_MODEL-egrid_PM25'] = poll_ds.sel(model_name = 'MODEL')['PM25']- poll_ds.sel(model_name = 'egrid')['PM25']\n",
    "poll_ds[f'dif_MODEL-egrid_PM25'].attrs['units'] = 'PM $\\mu$g m$^{-3}$'\n",
    "\n",
    "poll_ds = poll_ds.isel(lev = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<xarray.backends.zarr.ZarrStore at 0x7f09d58ab7d8>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xr.Dataset.to_zarr(poll_ds, 'model_NEI_egrid_GC_ds.zarr') #save the dataset "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EPA Observational data\n",
    "data is from https://aqs.epa.gov/aqsweb/airdata/download_files.html\n",
    "for the year 2016\n",
    "choosing O3, NO, SO2, PM25 (FEM/FRM)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPA_obs_df = pd.concat(map(pd.read_csv, glob.glob('../../GEOS_CHEM/obs_data/daily*.csv')))\n",
    "EPA_obs_df['date'] = pd.to_datetime(EPA_obs_df['Date Local'])\n",
    "EPA_obs_df['date'] = EPA_obs_df['date'].dt.normalize() + timedelta(hours=12)\n",
    "EPA_obs_df['Longitude'] = np.round(EPA_obs_df['Longitude'], decimals = 8)\n",
    "EPA_obs_df['Latitude'] = np.round(EPA_obs_df['Latitude'], decimals = 8)\n",
    "\n",
    "EPA_obs_df = EPA_obs_df.drop(columns = ['State Code','County Code','Site Num','Parameter Code','POC','Datum','Sample Duration','Date Local', 'Event Type',\n",
    "       'Observation Count', 'Observation Percent','1st Max Value', '1st Max Hour', 'Address', 'County Name', 'City Name',\n",
    "       'CBSA Name', 'Date of Last Change', 'Method Name'])\n",
    "\n",
    "#only use the SO2 1 hour 2010 pollutant standard arithmetic means and drop the 3-hour 1971 arithmetic means\n",
    "EPA_obs_df = EPA_obs_df.loc[~(EPA_obs_df['Pollutant Standard'] == 'SO2 3-hour 1971')]\n",
    "EPA_obs_df = EPA_obs_df.rename(columns = {'Parameter Name':'species'})\n",
    "\n",
    "#convert Ozone to ppb\n",
    "EPA_obs_df.loc[EPA_obs_df['species'] == 'Ozone','Arithmetic Mean'] *= 1e3 #ppb\n",
    "EPA_obs_df = EPA_obs_df.loc[~(EPA_obs_df['Arithmetic Mean'] <= 0)]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lists/Dicts of Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define Lat and Lon of the nested grid US\n",
    "levels_dict = {'PM25':np.arange(0., 20., .5), 'SO2':np.arange(0., 5., .1), \n",
    "               'NO2':np.arange(0., 5., .1), 'NOx':np.arange(0., 5., .1), 'O3':np.arange(0., 70., 1.),\n",
    "               'dif':np.arange(-.3, .31, .01), 'regional_dif':np.arange(-1.5, 1.51, .01)}\n",
    "\n",
    "\n",
    "#model_names = []\n",
    "#for d in datasets:    \n",
    "    #model_names.append(d.attrs['name'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stats on Observations vs. Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interpolate data to get GC run data at observational points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### interpolate data\n",
    "interp_df = pd.DataFrame(columns=['Arithmetic Mean', 'Longitude', 'Latitude','model','species','date'])\n",
    "\n",
    "for model in model_names:\n",
    "    for species in list(utils.species_dict.keys()):\n",
    "        for month in pd.DatetimeIndex(EPA_obs_df.loc[EPA_obs_df.date.dt.month.isin(utils.month_string)]['date'].values).month.unique().values:\n",
    "\n",
    "            #data selected for date\n",
    "            data = poll_ds.sel(model_name = model)[f'{species}'].groupby('time.month').mean().sel(month = month)\n",
    "            \n",
    "            #new lat and lon in radians\n",
    "            lats_new = EPA_obs_df.loc[(EPA_obs_df['species'] == utils.species_dict[species])]['Latitude'].unique()\n",
    "            lons_new = EPA_obs_df.loc[(EPA_obs_df['species'] == utils.species_dict[species])]['Longitude'].unique()\n",
    "            \n",
    "            #interpolation function\n",
    "            #interp_spline= RectBivariateSpline(lats, lons, data)\n",
    "            #interp_data = interp_spline(lats_new,lons_new,grid = False)\n",
    "            interp_data = []\n",
    "            for idx in range(lats_new.size):\n",
    "                interp_data.append(data.sel(lat=lats_new[idx], lon=lons_new[idx], method='nearest').values.item())\n",
    "            \n",
    "            tmp_df = pd.DataFrame({'Arithmetic Mean':interp_data, 'Longitude':lons_new, 'Latitude':lats_new, 'model': model, 'species': utils.species_dict[species], 'date': month})\n",
    "            interp_df = interp_df.append(tmp_df, sort=False, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, len(interp_df)):\n",
    "    interp_df.loc[i,('date')] = datetime(2016,interp_df['date'][i],calendar.monthrange(2016,interp_df['date'][i])[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a monthly EPA observational dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf = geopandas.GeoDataFrame(\n",
    "    EPA_obs_df, geometry=geopandas.points_from_xy(EPA_obs_df.Longitude, EPA_obs_df.Latitude))\n",
    "\n",
    "geometries = gdf['geometry'].apply(lambda x: x.wkt).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPA_obs_df['geometry'] = geometries\n",
    "EPA_obs_df.index = EPA_obs_df['date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "monthly_EPA_df = pd.DataFrame(columns = ['Arithmetic Mean','latitude','longitude', 'geometry','species', 'date'])\n",
    "for geometry in np.unique(geometries):\n",
    "    for species in np.unique(EPA_obs_df['species'].values):\n",
    "        lat = EPA_obs_df.loc[(EPA_obs_df['geometry'] == geometry) & (EPA_obs_df['species'] == species)].groupby(pd.Grouper(freq='M'))['Latitude'].first().values\n",
    "        lon = EPA_obs_df.loc[(EPA_obs_df['geometry'] == geometry) & (EPA_obs_df['species'] == species)].groupby(pd.Grouper(freq='M'))['Longitude'].first().values\n",
    "        data = EPA_obs_df.loc[(EPA_obs_df['geometry'] == geometry) & (EPA_obs_df['species'] == species)].groupby(pd.Grouper(freq='M'))['Arithmetic Mean'].mean()\n",
    "        tmp_df = pd.DataFrame({'Arithmetic Mean': data.values, 'latitude':lat, 'longitude':lon, \n",
    "                               'geometry':geometry, 'species': species, 'date': data.index})\n",
    "        monthly_EPA_df = monthly_EPA_df.append(tmp_df, sort=False, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add Region Names to the dataframes and save out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add region to the dataframes based on lat_lon dictionary\n",
    "interp_df['Region'] = 'a'\n",
    "EPA_obs_df['Region'] = 'a'\n",
    "monthly_EPA_df['Region'] = 'a'\n",
    "\n",
    "for region in ['SE_lat_lon','NW_lat_lon','NE_lat_lon','MW_lat_lon','SW_lat_lon']: \n",
    "    EPA_obs_df.loc[\n",
    "        (EPA_obs_df['Longitude'].between(utils.lat_lon_dict[region][0], utils.lat_lon_dict[region][1], inclusive = True)) & (EPA_obs_df['Latitude'].between(utils.lat_lon_dict[region][2], utils.lat_lon_dict[region][3], inclusive = True)), 'Region'] = region\n",
    "    interp_df.loc[\n",
    "        (interp_df['Longitude'].between(utils.lat_lon_dict[region][0], utils.lat_lon_dict[region][1], inclusive = True)) & (interp_df['Latitude'].between(utils.lat_lon_dict[region][2], utils.lat_lon_dict[region][3], inclusive = True)), 'Region'] = region\n",
    "    monthly_EPA_df.loc[\n",
    "        (monthly_EPA_df['longitude'].between(utils.lat_lon_dict[region][0], utils.lat_lon_dict[region][1], inclusive = True)) & (monthly_EPA_df['latitude'].between(utils.lat_lon_dict[region][2], utils.lat_lon_dict[region][3], inclusive = True)), 'Region'] = region\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "interp_df.to_csv('interp_df.csv', date_format='%Y%m%d', index=False)\n",
    "EPA_obs_df.to_csv('EPA_obs_df.csv', date_format='%Y%m%d', index=False)\n",
    "monthly_EPA_df.to_csv('EPA_monthly_obs_df.csv', date_format='%Y%m%d', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
